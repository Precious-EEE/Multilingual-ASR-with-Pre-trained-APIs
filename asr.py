# -*- coding: utf-8 -*-
"""ASR.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HsVl8lkb2C6TLJQNOAumRBF8h97XfiwW
"""

pip install SpeechRecognition pydub torch transformers streamlit

!pip install ffmpeg-python
import ffmpeg

input_file = '/content/input_audio_file.mp3'
output_file = '/content/input_audio_file.wav'

try:
    # Convert the audio file to WAV format
    (
        ffmpeg
        .input(input_file)
        .output(output_file, acodec='pcm_s16le', ac=1, ar='16k') # Set audio codec, channels, and sample rate for better speech recognition
        .run(overwrite_output=True) # Overwrite output file if it exists
    )
    print(f"Successfully converted '{input_file}' to '{output_file}'")
except ffmpeg.Error as e:
    print(f"Error converting audio: {e}")

import speech_recognition as sr

def transcribe_audio(file_path, language):
    recognizer = sr.Recognizer()
    with sr.AudioFile(file_path) as source:
        audio = recognizer.record(source)
    try:
        return recognizer.recognize_google(audio, language=language)
    except sr.UnknownValueError:
        return "Audio not understood"
    except sr.RequestError:
        return "API unavailable"

# Example usage
print(transcribe_audio(output_file, "en-US"))

input_file_1 = '/content/soft-lullaby-in-spanish-28361.mp3'
output_file_1 = '/content/soft-lullaby-in-spanish-28361.wav'

try:
    # Convert the audio file to WAV format
    (
        ffmpeg
        .input(input_file_1)
        .output(output_file_1, acodec='pcm_s16le', ac=1, ar='16k') # Set audio codec, channels, and sample rate for better speech recognition
        .run(overwrite_output=True) # Overwrite output file if it exists
    )
    print(f"Successfully converted '{input_file_1}' to '{output_file_1}'")
except ffmpeg.Error as e:
    print(f"Error converting audio: {e}")

print(transcribe_audio(output_file_1, "es-ES"))

from transformers import pipeline

whisper_asr = pipeline("automatic-speech-recognition", model="openai/whisper-large")

# Transcribe an audio file
result = whisper_asr("/content/astral-creepy-dark-logo-254198.mp3")
print(result['text'])

import streamlit as st
from transformers import pipeline

st.title("Multilingual ASR")
whisper_asr = pipeline("automatic-speech-recognition", model="openai/whisper-large")

uploaded_file = st.file_uploader("Upload Audio File")
if uploaded_file:
    with open("temp_audio.mp3", "wb") as f:
        f.write(uploaded_file.read())
    result = whisper_asr("temp_audio.mp3")
    st.write("Transcription:", result['text'])

